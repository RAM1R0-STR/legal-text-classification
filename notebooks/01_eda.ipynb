{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2527859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "plt.style.use(\"ggplot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66bfc430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>case_outcome</th>\n",
       "      <th>case_title</th>\n",
       "      <th>case_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Case1</td>\n",
       "      <td>cited</td>\n",
       "      <td>Alpine Hardwood (Aust) Pty Ltd v Hardys Pty Lt...</td>\n",
       "      <td>Ordinarily that discretion will be exercised s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Case2</td>\n",
       "      <td>cited</td>\n",
       "      <td>Black v Lipovac [1998] FCA 699 ; (1998) 217 AL...</td>\n",
       "      <td>The general principles governing the exercise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Case3</td>\n",
       "      <td>cited</td>\n",
       "      <td>Colgate Palmolive Co v Cussons Pty Ltd (1993) ...</td>\n",
       "      <td>Ordinarily that discretion will be exercised s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Case4</td>\n",
       "      <td>cited</td>\n",
       "      <td>Dais Studio Pty Ltd v Bullett Creative Pty Ltd...</td>\n",
       "      <td>The general principles governing the exercise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Case5</td>\n",
       "      <td>cited</td>\n",
       "      <td>Dr Martens Australia Pty Ltd v Figgins Holding...</td>\n",
       "      <td>The preceding general principles inform the ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  case_id case_outcome                                         case_title  \\\n",
       "0   Case1        cited  Alpine Hardwood (Aust) Pty Ltd v Hardys Pty Lt...   \n",
       "1   Case2        cited  Black v Lipovac [1998] FCA 699 ; (1998) 217 AL...   \n",
       "2   Case3        cited  Colgate Palmolive Co v Cussons Pty Ltd (1993) ...   \n",
       "3   Case4        cited  Dais Studio Pty Ltd v Bullett Creative Pty Ltd...   \n",
       "4   Case5        cited  Dr Martens Australia Pty Ltd v Figgins Holding...   \n",
       "\n",
       "                                           case_text  \n",
       "0  Ordinarily that discretion will be exercised s...  \n",
       "1  The general principles governing the exercise ...  \n",
       "2  Ordinarily that discretion will be exercised s...  \n",
       "3  The general principles governing the exercise ...  \n",
       "4  The preceding general principles inform the ex...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = Path(\"../data/raw/legal_text_classification.csv\")  # ajustá nombre\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fca7637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 24985 entries, 0 to 24984\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype\n",
      "---  ------        --------------  -----\n",
      " 0   case_id       24985 non-null  str  \n",
      " 1   case_outcome  24985 non-null  str  \n",
      " 2   case_title    24985 non-null  str  \n",
      " 3   case_text     24809 non-null  str  \n",
      "dtypes: str(4)\n",
      "memory usage: 780.9 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "case_outcome\n",
       "cited            12219\n",
       "referred to       4384\n",
       "applied           2448\n",
       "followed          2256\n",
       "considered        1712\n",
       "discussed         1024\n",
       "distinguished      608\n",
       "related            113\n",
       "affirmed           113\n",
       "approved           108\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()\n",
    "df['case_outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85398dec",
   "metadata": {},
   "source": [
    "En este bloque se limpian los textos legales para que el modelo pueda analizarlos mejor. Convertimos todo a minúsculas para evitar que “Court” y “court” se consideren diferentes palabras. Eliminamos números y signos de puntuación porque no aportan valor semántico para la clasificación. Luego quitamos las “stopwords” (palabras muy comunes como “the”, “and”, “of”) porque aparecen en casi todos los textos y no ayudan a diferenciar categorías. Finalmente, creamos una nueva columna con el texto limpio que será la base del análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad503025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\LR-300\\Documents\\legal-text-classification\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a588b33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LR-300\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m     tokens = [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stop_words]  \u001b[38;5;66;03m# quitar stopwords\u001b[39;00m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(tokens)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mclean_text\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcase_text\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m df[[\u001b[33m'\u001b[39m\u001b[33mcase_text\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mclean_text\u001b[39m\u001b[33m'\u001b[39m]].head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LR-300\\Documents\\legal-text-classification\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:5084\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4960\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4961\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4962\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4966\u001b[39m     **kwargs,\n\u001b[32m   4967\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4968\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4969\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4970\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5076\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   5077\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   5078\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5079\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5080\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5081\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5082\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5083\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m5084\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LR-300\\Documents\\legal-text-classification\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1520\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1517\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1519\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LR-300\\Documents\\legal-text-classification\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1578\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1576\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1577\u001b[39m     curried = func\n\u001b[32m-> \u001b[39m\u001b[32m1578\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1580\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1581\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1582\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1583\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LR-300\\Documents\\legal-text-classification\\.venv\\Lib\\site-packages\\pandas\\core\\base.py:1020\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action)\u001b[39m\n\u001b[32m   1017\u001b[39m arr = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   1019\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m-> \u001b[39m\u001b[32m1020\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms.map_array(arr, mapper, na_action=na_action)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LR-300\\Documents\\legal-text-classification\\.venv\\Lib\\site-packages\\pandas\\core\\arrays\\base.py:2692\u001b[39m, in \u001b[36mExtensionArray.map\u001b[39m\u001b[34m(self, mapper, na_action)\u001b[39m\n\u001b[32m   2672\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, mapper, na_action: Literal[\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   2673\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2674\u001b[39m \u001b[33;03m    Map values using an input mapping or function.\u001b[39;00m\n\u001b[32m   2675\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2690\u001b[39m \u001b[33;03m        a MultiIndex will be returned.\u001b[39;00m\n\u001b[32m   2691\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2692\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LR-300\\Documents\\legal-text-classification\\.venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1710\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action)\u001b[39m\n\u001b[32m   1708\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1709\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1710\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1711\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1712\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(values, mapper, mask=isna(values).view(np.uint8))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:3071\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mclean_text\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclean_text\u001b[39m(text):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     text = \u001b[43mtext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m()  \u001b[38;5;66;03m# convertir a minúsculas\u001b[39;00m\n\u001b[32m      9\u001b[39m     text = re.sub(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m[^a-zA-Z\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms]\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, text)  \u001b[38;5;66;03m# eliminar números y signos\u001b[39;00m\n\u001b[32m     10\u001b[39m     tokens = text.split()  \u001b[38;5;66;03m# dividir por espacios\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # convertir a minúsculas\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # eliminar números y signos\n",
    "    tokens = text.split()  # dividir por espacios\n",
    "    tokens = [t for t in tokens if t not in stop_words]  # quitar stopwords\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['clean_text'] = df['case_text'].astype(str).apply(clean_text)\n",
    "df[['case_text','clean_text']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b384deb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'clean_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LR-300\\Documents\\legal-text-classification\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3641\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3640\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3642\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:168\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:197\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7668\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7676\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'clean_text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m all_words = \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclean_text\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m).split()\n\u001b[32m      2\u001b[39m freq = Counter(all_words)\n\u001b[32m      4\u001b[39m common = freq.most_common(\u001b[32m20\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LR-300\\Documents\\legal-text-classification\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4378\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4378\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4380\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LR-300\\Documents\\legal-text-classification\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3648\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3643\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3644\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3645\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3646\u001b[39m     ):\n\u001b[32m   3647\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3649\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3650\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3651\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3652\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3653\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'clean_text'"
     ]
    }
   ],
   "source": [
    "all_words = \" \".join(df['clean_text']).split()\n",
    "freq = Counter(all_words)\n",
    "\n",
    "common = freq.most_common(20)\n",
    "\n",
    "words, counts = zip(*common)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(words, counts)\n",
    "plt.xticks(rotation=70)\n",
    "plt.title(\"Top 20 palabras más frecuentes\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57514c86",
   "metadata": {},
   "source": [
    "En este bloque convertimos el texto en números usando la técnica TF-IDF (Term Frequency – Inverse Document Frequency). Los modelos de machine learning no entienden texto directamente, así que necesitamos transformarlo en vectores numéricos. TF-IDF asigna mayor peso a palabras que son importantes en un documento pero no tan frecuentes en todos los documentos. Esto mejora la capacidad del modelo para distinguir categorías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7223689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "X = vectorizer.fit_transform(df['clean_text'])\n",
    "y = df['case_outcome']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
